{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jaekim/ws/git/myHDR/source')\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor(tensor, title=''):\n",
    "    tensor = tensor.squeeze().T\n",
    "    plt.imshow(tensor)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hist(tensor, boundary, bin=256):\n",
    "    np = tensor.squeeze().cpu().numpy().flatten()\n",
    "    plt.hist(np, bins=bin)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    for b in boundary:\n",
    "        plt.axvline(x=b, color='red', linestyle='--', label=f'Boundary: {b:.4f}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_by_hist_kmean(diff_tensor, k=2):\n",
    "    diff = diff_tensor.squeeze().cpu().numpy()  # shape: (H, W)\n",
    "    flat_diff = diff.reshape(-1, 1)\n",
    "\n",
    "    # K-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(flat_diff)  # shape: (H*W,)\n",
    "    centers = kmeans.cluster_centers_.squeeze()  # shape: (k,)\n",
    "    sorted_centers = np.sort(centers)  # e.g., [low, mid, high]\n",
    "    boundary = [(sorted_centers[i] + sorted_centers[i + 1]) / 2 for i in range(k - 1)]\n",
    "\n",
    "    # centers를 오름차순 정렬하여 [low, mid, high] → 0, 1, 2로 매핑\n",
    "    sorted_indices = np.argsort(centers)           # e.g., [2, 0, 1]\n",
    "    mask = np.zeros_like(labels)\n",
    "\n",
    "    for new_label, old_label in enumerate(sorted_indices):\n",
    "        mask[labels == old_label] = new_label\n",
    "\n",
    "    mask = mask.reshape(diff_tensor.shape).astype(np.uint8)\n",
    "\n",
    "    return mask, boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sat_map(label, mid_exp):\n",
    "    label_after_clamp = (label * mid_exp).clamp(0, 1) / mid_exp\n",
    "    saturated = torch.abs(label - label_after_clamp).mean(dim=0, keepdim=True)\n",
    "    sat_map = torch.where(saturated > 0, torch.ones_like(label), torch.zeros_like(label))\n",
    "    \n",
    "    return sat_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/74: 001.h5\n",
      "Processing 2/74: 002.h5\n",
      "Processing 3/74: 003.h5\n",
      "Processing 4/74: 004.h5\n",
      "Processing 5/74: 005.h5\n",
      "Processing 6/74: 006.h5\n",
      "Processing 7/74: 007.h5\n",
      "Processing 8/74: 008.h5\n",
      "Processing 9/74: 009.h5\n",
      "Processing 10/74: 010.h5\n",
      "Processing 11/74: 011.h5\n",
      "Processing 12/74: 012.h5\n",
      "Processing 13/74: 013.h5\n",
      "Processing 14/74: 014.h5\n",
      "Processing 15/74: 015.h5\n",
      "Processing 16/74: 016.h5\n",
      "Processing 17/74: 017.h5\n",
      "Processing 18/74: 018.h5\n",
      "Processing 19/74: 019.h5\n",
      "Processing 20/74: 020.h5\n",
      "Processing 21/74: 021.h5\n",
      "Processing 22/74: 022.h5\n",
      "Processing 23/74: 023.h5\n",
      "Processing 24/74: 024.h5\n",
      "Processing 25/74: 025.h5\n",
      "Processing 26/74: 026.h5\n",
      "Processing 27/74: 027.h5\n",
      "Processing 28/74: 028.h5\n",
      "Processing 29/74: 029.h5\n",
      "Processing 30/74: 030.h5\n",
      "Processing 31/74: 031.h5\n",
      "Processing 32/74: 032.h5\n",
      "Processing 33/74: 033.h5\n",
      "Processing 34/74: 034.h5\n",
      "Processing 35/74: 035.h5\n",
      "Processing 36/74: 036.h5\n",
      "Processing 37/74: 037.h5\n",
      "Processing 38/74: 038.h5\n",
      "Processing 39/74: 039.h5\n",
      "Processing 40/74: 040.h5\n",
      "Processing 41/74: 041.h5\n",
      "Processing 42/74: 042.h5\n",
      "Processing 43/74: 043.h5\n",
      "Processing 44/74: 044.h5\n",
      "Processing 45/74: 045.h5\n",
      "Processing 46/74: 046.h5\n",
      "Processing 47/74: 047.h5\n",
      "Processing 48/74: 048.h5\n",
      "Processing 49/74: 049.h5\n",
      "Processing 50/74: 050.h5\n",
      "Processing 51/74: 051.h5\n",
      "Processing 52/74: 052.h5\n",
      "Processing 53/74: 053.h5\n",
      "Processing 54/74: 054.h5\n",
      "Processing 55/74: 055.h5\n",
      "Processing 56/74: 056.h5\n",
      "Processing 57/74: 057.h5\n",
      "Processing 58/74: 058.h5\n",
      "Processing 59/74: 059.h5\n",
      "Processing 60/74: 060.h5\n",
      "Processing 61/74: 061.h5\n",
      "Processing 62/74: 062.h5\n",
      "Processing 63/74: 063.h5\n",
      "Processing 64/74: 064.h5\n",
      "Processing 65/74: 065.h5\n",
      "Processing 66/74: 066.h5\n",
      "Processing 67/74: 067.h5\n",
      "Processing 68/74: 068.h5\n",
      "Processing 69/74: 069.h5\n",
      "Processing 70/74: 070.h5\n",
      "Processing 71/74: 071.h5\n",
      "Processing 72/74: 072.h5\n",
      "Processing 73/74: 073.h5\n",
      "Processing 74/74: 074.h5\n"
     ]
    }
   ],
   "source": [
    "h5_dir = '/home/jaekim/ws/data/Kalantari/HDF/aligned/Training'\n",
    "\n",
    "h5_paths = [os.path.join(h5_dir, f) for f in os.listdir(h5_dir) if f.endswith('.h5')]\n",
    "\n",
    "for i, path in enumerate(h5_paths):\n",
    "    file_name = os.path.basename(path)\n",
    "    print(f'Processing {i + 1}/{len(h5_paths)}: {file_name}')\n",
    "    with h5py.File(path, 'r+') as f:\n",
    "        data1 = f['IN'][3*3:4*3, :, :]  # short after gain adjustment\n",
    "        data2 = f['IN'][4*3:5*3, :, :]  # mid after gain adjustment\n",
    "        data3 = f['IN'][5*3:6*3, :, :]  # long after gain adjustment\n",
    "        label = f['GT'][   :   , :, :]\n",
    "        exp  = f['EXP'][:]\n",
    "        \n",
    "        data1 = torch.from_numpy(data1).float()\n",
    "        data2 = torch.from_numpy(data2).float()\n",
    "        data3 = torch.from_numpy(data3).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "        \n",
    "        # TODO: put map function here (before tonemapping)\n",
    "        sat_map = get_sat_map(label, exp[1])\n",
    "        \n",
    "        \n",
    "        # TODO: put map function here (after tonemapping)\n",
    "        #data1 = tonemap(data1, 'mu')\n",
    "        #data2 = tonemap(data2, 'mu')\n",
    "        #data3 = tonemap(data3, 'mu')\n",
    "        #label = tonemap(label, 'mu')\n",
    "        \n",
    "        \n",
    "        # TODO : write map to h5\n",
    "        write_map_key = 'MAP_sat'\n",
    "        write_map_data = sat_map\n",
    "        \n",
    "        \n",
    "        if write_map_key in f:\n",
    "            del f[write_map_key]\n",
    "        f.create_dataset(write_map_key, data=sat_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
